{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommender System\n",
    "\n",
    "A recommender system is a system that attempts to predict the rating or preference a user would give to a certain item.\n",
    "In this case, it is intended to create a movie recommender system.\n",
    "\n",
    "A popular algorithm for these kind of systems is the Singular Value Decomposition (SVD), that has been utilized to achieve better results, as it will be demonstrated ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The MovieLens Dataset is most often used for the purpose of recommender systems, which aim to predict user movie ratings based on other users’ ratings.\n",
    "\n",
    "The dataset used was extracted from MovieLens and contains 100836 ratings and 3683 tag applications across 9742 movies. This data was created by 610 users between March 29, 1996 and September 24, 2018.\n",
    "\n",
    "The data are contained in the files:\n",
    "- Movies.csv: movieId, title, genres.\n",
    "- Ratings.csv: userId, movieId, rating, timestamp.\n",
    "- Tags.csv: userId, movieId, tag, timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p6/n3vpmbmn2s15fhn83qmld1800000gn/T/ipykernel_2679/2987547969.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mr_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'movie_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rating'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ml-100k/u.data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from funk_svd.dataset import fetch_ml_ratings\n",
    "from funk_svd import SVD\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    " \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from funk_svd.dataset import fetch_ml_ratings\n",
    "from funk_svd import SVD\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Movie Data\n",
    "i_cols = ['movie_id', 'title' ,'release date','video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure',\n",
    "'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "movies = pd.read_csv('ml-100k/u.item',  sep='|', names=i_cols, encoding='latin-1')\n",
    "\n",
    "movies.head()\n",
    "\n",
    "num_movies = len(movies)\n",
    "\n",
    "print(num_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-100k/u.user', sep='|', names=u_cols, encoding='latin-1')\n",
    "\n",
    "users.head()\n",
    "\n",
    "num_users = len(users)\n",
    "\n",
    "print(num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "\n",
    "ratings = pd.read_csv(\"ml-100k/u.data\", sep=\"\\t\", names=r_cols, encoding='latin-1')\n",
    "\n",
    "ratings.head()\n",
    "\n",
    "ratings.describe()\n",
    "\n",
    "print(len(ratings.user_id.unique()))\n",
    "print(len(ratings.movie_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparsity\n",
    "\n",
    "The Sparsity of a matrix is measured by the number of cells that do not have a value.\n",
    "As it can be seen bellow, the matrix of ratings in this dataset is going to be very sparse, having a sparsity of 93.7%,\n",
    "which means that the majority of users only rated a small percentage of the movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = 1 - len(ratings) / (num_users * num_movies)\n",
    "\n",
    "print(f\"Sparsity: {sparsity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ratings.rating, ec='black', bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5])\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Number of Ratings\")\n",
    "plt.title(\"Distribution of Ratings\")\n",
    "plt.xticks([1, 2, 3, 4, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix = ratings.pivot(index=\"user_id\", columns=\"movie_id\", values=\"rating\")\n",
    "\n",
    "print(ratings_matrix.shape)\n",
    "print(ratings_matrix.iloc[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen above, there are NaN entries on the matrix, which need to be replaced by some other value in order to perform the SVD.\n",
    "\n",
    "There are several approaches to this problem, such as replacing with zero value, or average of all ratings, or even the average rating of a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix = ratings_matrix.fillna(0)\n",
    "print(ratings_matrix.iloc[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sparsity mentioned above, can be verified by the percentage of zeros present in the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = 1 - np.count_nonzero(ratings_matrix) / (num_users * num_movies)\n",
    "print(f\"Sparsity: {sparsity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD\n",
    "\n",
    "Opa ya é o svd e tal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, VT = np.linalg.svd(ratings_matrix, full_matrices=False)\n",
    "\n",
    "print(f\"U: {pd.DataFrame(U).iloc[:5, :5]}\")\n",
    "print(f\"S: {pd.DataFrame(S).iloc[:5, :]}\")\n",
    "print(f\"VT: {pd.DataFrame(VT).iloc[:5, :5]}\")\n",
    "print(U.shape)\n",
    "print(S.shape)\n",
    "print(VT.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Matrix Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_matrix = np.dot(U * S, VT)\n",
    "\n",
    "print(reconstructed_matrix[1][:4])\n",
    "print(ratings_matrix.iloc[1, :4].to_numpy())\n",
    "\n",
    "mae = np.average(np.absolute(ratings_matrix - reconstructed_matrix))\n",
    "print(\"Reconstruction Error: \", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncated SVD\n",
    "dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_matrix = np.dot(U[:,:10] * S[:10], VT[:10,:])\n",
    "mae = np.average(np.absolute(ratings_matrix - reconstructed_matrix))\n",
    "print(\"Reconstruction Error: \", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funk SVD\n",
    "\n",
    "Fetches dataset\n",
    "\n",
    "Splits data\n",
    "\n",
    "Trains with learning rate..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve dataset with 100k rows\n",
    "df = fetch_ml_ratings(variant='100k')\n",
    "\n",
    "train = df.sample(frac=0.8, random_state=7)\n",
    "val = df.drop(train.index.tolist()).sample(frac=0.5, random_state=8)\n",
    "test = df.drop(train.index.tolist()).drop(val.index.tolist())\n",
    "\n",
    "svd = SVD(lr=0.001, reg=0.005, n_epochs=100, n_factors=15, early_stopping=True,\n",
    "          shuffle=False, min_rating=1, max_rating=5)\n",
    "\n",
    "svd.fit(X=train, X_val=val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE RMSE w/e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = svd.predict(test)\n",
    "mae = mean_absolute_error(test['rating'], pred)\n",
    "print(f'Test MAE: {mae:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [0.0001, 0.001, 0.01, 0.1]\n",
    "factors = [5, 10, 15, 20, 25, 30]\n",
    "\n",
    "mae_outputs = {}\n",
    "for lr in lrs:\n",
    "\tfor n in factors:\n",
    "\t\tsvd = SVD(lr=lr, n_epochs=100, n_factors=n, early_stopping=False,\n",
    "\t\t\tshuffle=False, min_rating=1, max_rating=5)\n",
    "\n",
    "\t\tsvd.fit(X=train, X_val=val)\n",
    "\n",
    "\t\tpred = svd.predict(test)\n",
    "\t\tmae = mean_absolute_error(test['rating'], pred)\n",
    "\t\tmae_outputs.setdefault(lr, [])\n",
    "\t\tmae_outputs[lr].append(mae)\n",
    "\t\tprint(f'Latent Factors: {n}\\nLearning Rate: {lr}\\nTest MAE: {mae:.2f}')\n",
    "\n",
    "for lr in mae_outputs:\n",
    "\tplt.plot(factors, mae_outputs[lr], label=f\"lr={lr}\")\n",
    "\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.xlabel(\"Number of Latent Factors\")\n",
    "plt.xticks(factors)\n",
    "plt.title(\"Funk SVD MAE with different Latent Factors and Learning Rates\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "opt_lr, lr_n_factors = min(mae_outputs.items(), key=lambda x: min(x[1]))\n",
    "opt_n_factor = factors[lr_n_factors.index(min(lr_n_factors))]\n",
    "\n",
    "print(f\"Optimal Learning Rate: {opt_lr}\")\n",
    "print(f\"Optimal Number of Latent Factors: {opt_n_factor}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict for a rating of a user for non rated movies example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVD with optimal hyperparameters calculated previously\n",
    "svd = SVD(lr=0.01, n_epochs=100, n_factors=10, early_stopping=False,\n",
    "\t\t\tshuffle=False, min_rating=1, max_rating=5)\n",
    "\n",
    "svd.fit(X=train, X_val=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 1\n",
    "# hand selected a movie that was rated by the user\n",
    "movie_id_rated = 1\n",
    "# hand selected a movie that wasn't rated by the user\n",
    "movie_id_unrated = 1682\n",
    "\n",
    "# initialize prediction to global mean rating\n",
    "pred = svd.global_mean_\n",
    "\n",
    "# getting index assigned to the user_id by the Funk SVD\n",
    "u_ix = svd.user_mapping_[user_id]\n",
    "\n",
    "# adding the bias associated with this user id\n",
    "pred += svd.bu_[u_ix]\n",
    "\n",
    "# getting index assigned to the movie_id by the Funk SVD\n",
    "i_ix_unrated = svd.item_mapping_[movie_id_unrated]\n",
    "i_ix_rated = svd.item_mapping_[movie_id_rated]\n",
    "\n",
    "# adding the bias associated with this user id\n",
    "pred_unrated = pred + svd.bi_[i_ix_unrated]\n",
    "pred_rated = pred + svd.bi_[i_ix_rated]\n",
    "\n",
    "# dot product between the associated user's and movie's latent factors\n",
    "pred_unrated += np.dot(svd.pu_[u_ix], svd.qi_[i_ix_unrated])\n",
    "pred_rated += np.dot(svd.pu_[u_ix], svd.qi_[i_ix_rated])\n",
    "\n",
    "print(f\"For user id: {user_id}\")\n",
    "print(f\"Rating prediction for a rated movie {movie_id_rated}: {pred_rated:.1f},\\\n",
    "\tActual Rating: {ratings_matrix.iloc[user_id - 1, movie_id_rated - 1]}\")\n",
    "print(f\"Rating prediction for an unrated movie {movie_id_unrated}: {pred_unrated:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Analysis\n",
    "\n",
    "Calculate cosine similarity, sort by most similar and return the top N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_cosine_similarity(data, item_id, top_n=10):\n",
    "    index = item_id - 1 #Ids starts from 1 in the dataset\n",
    "    row = data[index, :]\n",
    "    magnitude = np.sqrt(np.einsum('ij, ij -> i', data, data))\n",
    "    similarity = np.dot(row, data.T) / (magnitude[index] * magnitude)\n",
    "    sort_indexes = np.argsort(-similarity)\n",
    "    return sort_indexes[:top_n]\n",
    "\n",
    "# Function to print top N similar movies\n",
    "def print_similar_movies(movie_data, movie_id, top_indexes):\n",
    "    print('Recommendations for {0}: \\n'.format(\n",
    "        movie_data[movie_data.movie_id == movie_id].title.values[0]))\n",
    "    for id in top_indexes + 1:\n",
    "        print(movie_data[movie_data.movie_id == id].title.values[0])\n",
    "\n",
    "# Function to print top N similar users\n",
    "def print_similar_users(user_data, user_id, top_indexes):\n",
    "    print('Recommendations for {0}: \\n'.format(\n",
    "        user_data[user_data.user_id == user_id]))\n",
    "    for id in top_indexes + 1:\n",
    "        print(user_data[user_data.user_id == id])\n",
    "\n",
    "\n",
    "movie_id = 1\n",
    "user_id = 1\n",
    "top_n = 5\n",
    "top_indexes_movies = top_cosine_similarity(VT, movie_id, top_n)\n",
    "print_similar_movies(movies, movie_id, top_indexes_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in top_indexes_movies:\n",
    "\tplt.plot(U[i,0], U[i,1], 'o')\n",
    "\tplt.annotate(movies[movies.movie_id == i+1].title.values[0], (U[i,0], U[i,1]))\n",
    "\n",
    "plt.ylabel(\"Latent Factor 1\")\n",
    "plt.xlabel(\"Latent Factor 2\")\n",
    "plt.title(\"Normal SVD\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "top_indexes_users = top_cosine_similarity(U, user_id, top_n)\n",
    "print_similar_users(users, user_id, top_indexes_users)\n",
    "\n",
    "\n",
    "\n",
    "top_indexes_movies = top_cosine_similarity(svd.qi_, movie_id, top_n)\n",
    "print_similar_movies(movies, movie_id, top_indexes_movies)\n",
    "\n",
    "for i in top_indexes_movies:\n",
    "\tplt.plot(svd.qi_[i,0], svd.qi_[i,1], 'o')\n",
    "\tplt.annotate(movies[movies.movie_id == i+1].title.values[0], (svd.qi_[i,0], svd.qi_[i,1]))\n",
    "\n",
    "plt.ylabel(\"Latent Factor 1\")\n",
    "plt.xlabel(\"Latent Factor 2\")\n",
    "plt.title(\"Funk SVD\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "top_indexes_users = top_cosine_similarity(svd.pu_, user_id, top_n)\n",
    "print_similar_users(users, user_id, top_indexes_users)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3d64d6f9de24c9f5dacafd9593950391c00d6e68bc9522e9fed72e7acec3906"
  },
  "kernelspec": {
   "display_name": "Python 3.8.4rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
